# Airflow Environment Variables
# Copy this file to .env and configure for your environment

# ====================================================================================================
# Core Settings
# ====================================================================================================

# Airflow home directory
AIRFLOW_HOME=/home/yousef/workspace/storage/UZ2CcrTd13NrEAm81F1qLWHyAiD2/projects/rul-prediction-system/airflow

# RUL project root directory
RUL_PROJECT_ROOT=/home/yousef/workspace/storage/UZ2CcrTd13NrEAm81F1qLWHyAiD2/projects/rul-prediction-system

# Airflow UID (Linux/Mac only)
AIRFLOW_UID=50000

# Project directory for Docker Compose
AIRFLOW_PROJ_DIR=.

# ====================================================================================================
# Database Configuration
# ====================================================================================================

# PostgreSQL connection string (production)
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@localhost:5432/airflow

# SQLite connection string (development only)
# AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////path/to/airflow/airflow.db

# ====================================================================================================
# Executor Configuration
# ====================================================================================================

# Executor type: LocalExecutor, CeleryExecutor, KubernetesExecutor
AIRFLOW__CORE__EXECUTOR=LocalExecutor

# Celery broker URL (if using CeleryExecutor)
AIRFLOW__CELERY__BROKER_URL=redis://localhost:6379/0

# Celery result backend (if using CeleryExecutor)
AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@localhost:5432/airflow

# ====================================================================================================
# Web Server Configuration
# ====================================================================================================

# Web server host
AIRFLOW__WEBSERVER__WEB_SERVER_HOST=0.0.0.0

# Web server port
AIRFLOW__WEBSERVER__WEB_SERVER_PORT=8080

# Secret key for Flask session (generate with: python -c "import secrets; print(secrets.token_hex(32))")
AIRFLOW__WEBSERVER__SECRET_KEY=your_secret_key_here

# ====================================================================================================
# Authentication Configuration
# ====================================================================================================

# Admin user credentials
_AIRFLOW_WWW_USER_USERNAME=admin
_AIRFLOW_WWW_USER_PASSWORD=admin

# Auth backend
AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session

# ====================================================================================================
# Email Configuration
# ====================================================================================================

# SMTP host
AIRFLOW__SMTP__SMTP_HOST=smtp.gmail.com

# SMTP port
AIRFLOW__SMTP__SMTP_PORT=587

# SMTP user
AIRFLOW__SMTP__SMTP_USER=your-email@gmail.com

# SMTP password (use app-specific password for Gmail)
AIRFLOW__SMTP__SMTP_PASSWORD=your-app-password

# SMTP mail from
AIRFLOW__SMTP__SMTP_MAIL_FROM=airflow@example.com

# SMTP SSL/TLS
AIRFLOW__SMTP__SMTP_STARTTLS=true
AIRFLOW__SMTP__SMTP_SSL=false

# Alert email
ALERT_EMAIL=admin@example.com

# Success email
SUCCESS_EMAIL=team@example.com

# ====================================================================================================
# Slack Configuration (Optional)
# ====================================================================================================

# Slack webhook URL for notifications
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL

# ====================================================================================================
# Monitoring Configuration (Optional)
# ====================================================================================================

# StatsD configuration
AIRFLOW__METRICS__STATSD_ON=false
AIRFLOW__METRICS__STATSD_HOST=localhost
AIRFLOW__METRICS__STATSD_PORT=8125
AIRFLOW__METRICS__STATSD_PREFIX=airflow

# ====================================================================================================
# Logging Configuration
# ====================================================================================================

# Logging level
AIRFLOW__LOGGING__LOGGING_LEVEL=INFO

# Remote logging (S3, GCS, etc.)
AIRFLOW__LOGGING__REMOTE_LOGGING=false

# ====================================================================================================
# DAG Configuration
# ====================================================================================================

# Load examples
AIRFLOW__CORE__LOAD_EXAMPLES=false

# Catchup by default
AIRFLOW__SCHEDULER__CATCHUP_BY_DEFAULT=false

# DAG concurrency
AIRFLOW__CORE__DAG_CONCURRENCY=16

# Max active runs per DAG
AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG=16

# Parallelism
AIRFLOW__CORE__PARALLELISM=32

# ====================================================================================================
# Additional Python Requirements
# ====================================================================================================

# Additional pip packages to install
_PIP_ADDITIONAL_REQUIREMENTS=

# ====================================================================================================
# Model Training Configuration
# ====================================================================================================

# Training epochs
TRAINING_EPOCHS=100

# Learning rate
LEARNING_RATE=0.001

# Batch size
BATCH_SIZE=32

# ====================================================================================================
# Security Configuration (Production)
# ====================================================================================================

# Fernet key for encrypting connections (generate with: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())")
AIRFLOW__CORE__FERNET_KEY=

# ====================================================================================================
# Kubernetes Configuration (if using KubernetesExecutor)
# ====================================================================================================

# Kubernetes namespace
# AIRFLOW__KUBERNETES__NAMESPACE=airflow

# Worker image
# AIRFLOW__KUBERNETES__WORKER_CONTAINER_REPOSITORY=apache/airflow
# AIRFLOW__KUBERNETES__WORKER_CONTAINER_TAG=2.7.3
